{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849f6f12",
   "metadata": {},
   "source": [
    "This notebook is used to read in the CSVs from the Google Landmark data from Kaggle, do some intial data exploration, and then subset the list of image URLs to only those for landmarks we wish to use.\n",
    "\n",
    "Inputs: files from https://www.kaggle.com/google/google-landmarks-dataset\n",
    "\n",
    "Output: train_subset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a889caf8",
   "metadata": {},
   "source": [
    "Begin by reading in all required libraries. You may have to install these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d70b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, multiprocessing, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Deep Learning libraries\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcec39f",
   "metadata": {},
   "source": [
    "Import the data sets. These are found in the 'google-data' folder. I downloaded these straight from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cff45a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"google-data/train.csv\")\n",
    "num_classes = len(df[\"landmark_id\"].unique())\n",
    "num_data = len(df)\n",
    "\n",
    "df = df[df.landmark_id!='None'] # Removing any unlabeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090974ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97c0a12e07ae8dd5</td>\n",
       "      <td>http://lh4.ggpht.com/-f8xYA5l4apw/RSziSQVaABI/...</td>\n",
       "      <td>6347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>650c989dd3493748</td>\n",
       "      <td>https://lh5.googleusercontent.com/-PUnMrX7oOyA...</td>\n",
       "      <td>12519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05e63ca9b2cde1f4</td>\n",
       "      <td>http://mw2.google.com/mw-panoramio/photos/medi...</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08672eddcb2b7c93</td>\n",
       "      <td>http://lh3.ggpht.com/-9fgSxDYwhHA/SMvGEoltKTI/...</td>\n",
       "      <td>13287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fc49cb32ef7f1e89</td>\n",
       "      <td>http://lh6.ggpht.com/-UGAXxvPbr98/S-jGZbyMIPI/...</td>\n",
       "      <td>4018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  97c0a12e07ae8dd5  http://lh4.ggpht.com/-f8xYA5l4apw/RSziSQVaABI/...   \n",
       "1  650c989dd3493748  https://lh5.googleusercontent.com/-PUnMrX7oOyA...   \n",
       "2  05e63ca9b2cde1f4  http://mw2.google.com/mw-panoramio/photos/medi...   \n",
       "3  08672eddcb2b7c93  http://lh3.ggpht.com/-9fgSxDYwhHA/SMvGEoltKTI/...   \n",
       "4  fc49cb32ef7f1e89  http://lh6.ggpht.com/-UGAXxvPbr98/S-jGZbyMIPI/...   \n",
       "\n",
       "  landmark_id  \n",
       "0        6347  \n",
       "1       12519  \n",
       "2         264  \n",
       "3       13287  \n",
       "4        4018  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c01af808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data: (1154202, 3)\n",
      "Number of unique classes: 14945\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training data:\", df.shape)\n",
    "print(\"Number of unique classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20de909f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  landmark_id  count\n",
      "0        9633  48550\n",
      "1        6051  47825\n",
      "2        6599  21777\n",
      "3        9779  17601\n",
      "4        2061  12742\n",
      "5        5554  10302\n",
      "6        6651   8950\n",
      "7        5376   8893\n",
      "8        6696   8885\n",
      "9        4352   8689\n",
      "      landmark_id  count\n",
      "14934        7933      1\n",
      "14935        1913      1\n",
      "14936       10535      1\n",
      "14937        6423      1\n",
      "14938        9559      1\n",
      "14939        8309      1\n",
      "14940        5030      1\n",
      "14941        3022      1\n",
      "14942       14180      1\n",
      "14943        7977      1\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(df['landmark_id'].value_counts())\n",
    "\n",
    "#index the data frame\n",
    "data.reset_index(inplace=True) \n",
    "data.columns=['landmark_id','count']\n",
    "print(data.head(10))\n",
    "print(data.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b29b520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    14944.000000\n",
      "mean        77.235145\n",
      "std        675.090417\n",
      "min          1.000000\n",
      "25%          6.000000\n",
      "50%         13.000000\n",
      "75%         43.000000\n",
      "max      48550.000000\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Occurences')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data['count'].describe())#statistical data for the distribution\n",
    "plt.hist(data['count'],100,range = (0,8000),label = 'test')#Histogram of the distribution\n",
    "plt.xlabel(\"Amount of images\")\n",
    "plt.ylabel(\"Occurences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a82db60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of classes with less than or equal to five datapoints: 3592\n",
      "Amount of classes between five and 10 datapoints: 4421\n"
     ]
    }
   ],
   "source": [
    "print(\"Amount of classes with less than or equal to five datapoints:\", (data['count'].between(0,5)).sum()) \n",
    "print(\"Amount of classes between five and 10 datapoints:\", (data['count'].between(5,10)).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e83eda",
   "metadata": {},
   "source": [
    "It looks like the majority of classes have few occurances. Let's see how many images are left in our training set when we put a bound on the required number of images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34d858fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8240"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding number of classes with more than 10 images\n",
    "above10 = data[data['count']>10]\n",
    "len(above10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a61b3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1116911"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subsetting training data to images in classes with >10 images\n",
    "df_above10 = df[df['landmark_id'].isin(above10['landmark_id'])]\n",
    "len(df_above10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c875fbba",
   "metadata": {},
   "source": [
    "This is still over a million images, which is infeasible for us to use unless we want to use some cloud service and spend >20 hours downloading all the images (number taken from this article: https://medium.com/@abhinaya08/google-landmark-recognition-274aab3c71ae).\n",
    "\n",
    "To put in perspective how many classes have a huge number of images, we still have about 250k images when we restrict the traing dataset to those in classes with over 4,000 images. This would take around 6 hours to download. That is doable, but still annoying.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a727dccc",
   "metadata": {},
   "source": [
    "### Subsetting images considerations\n",
    "\n",
    "Some thoughts on how to subset images:\n",
    "\n",
    "- Dealing with imbalanced data is annoying--having a training dataset with one class that has 100 images and another with 5000 images will lead to our classification model poorly predicting images of the former class. I vote we stick to classes with a somewhat equal amount of images. So for example we only keep images in classes where the number of images is something in the range of [750,1000].\n",
    "    \n",
    "- One option could be to take the first N instances of images in each class. So for example we keep all images in classes with over 100 images, but if the class has over 100 images, we only take the first 100 images from that class. That is a way of balancing our data, but personally I don't feel it's necessary since we have already a ton of classes in the example range I set above. It could also lead to unwanted bias in our results since we're arbitrarily removing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e53675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "66040\n"
     ]
    }
   ],
   "source": [
    "# Subsetting the training data to fit the example range of (classes in [750,1000])\n",
    "\n",
    "exRange = data[data['count'].between(750,1000)]\n",
    "print(len(exRange))\n",
    "\n",
    "df_exRange = df[df['landmark_id'].isin(exRange['landmark_id'])]\n",
    "print(len(df_exRange))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99511a24",
   "metadata": {},
   "source": [
    "We have 78 classes in which the number of images is in the range of (750,1000). This results in 66,040 images in total when we restrict the training data to only images in those classes. This is feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5c574e",
   "metadata": {},
   "source": [
    "### Test data considerations\n",
    "\n",
    "Now an important thing to note is that test.csv contains UNLABELED data, as this dataset is used for a Kaggle competition and thus contestants are not given ground truth for the test samples.\n",
    "\n",
    "In fact the link that Mark provided from analyticsvidhya does not produce any test error at all--if you look at their code under the sentence \"Our next step is to test the model, let’s see the results of our trained landmark detection model:\", you'll see that they're predicting the training images to calculate the error.\n",
    "\n",
    "Because we do not have the ground truth of images in test.csv, we'll have to manually split our training data into training/validation/test sets. This is super easy and is actually kind of nice because we know for certain our test images are in the same classes as our training images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d445262e",
   "metadata": {},
   "source": [
    "## Downloading images\n",
    "\n",
    "I want to make sure we can successfully download the 66,040 images we need. Based on my estimates this would still require some 10-14 GBs which my tiny mac cannot handle. I'm going to make the problem even smaller just to see if I can get the images donwloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c88ae25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "10979\n"
     ]
    }
   ],
   "source": [
    "# Subsetting the training data to fit in an even SMALLER range of (900,950)\n",
    "\n",
    "smallRange = data[data['count'].between(900,950)]\n",
    "print(len(smallRange))\n",
    "\n",
    "df_smallRange = df[df['landmark_id'].isin(smallRange['landmark_id'])]\n",
    "print(len(df_smallRange))\n",
    "\n",
    "# This yields 12 classes and just over 10k images. Let's see if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a732609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see where I am in my system\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6791266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing csv of this small subset of images\n",
    "df_smallRange.to_csv('google-data/train_subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c86bd7",
   "metadata": {},
   "source": [
    "After running my modified version of the download file I was able to get 10,353 of the images. The rest were broken links. This took about 45 minutes to download and around 6GB of storage. If we want to use more images I'll definitely have to use a cloud system because I only have 4GB left on my computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991abd94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
